{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b93f9c-cf78-44b6-b768-dc44150ac155",
   "metadata": {},
   "source": [
    "Семинар\n",
    "1 пункт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77da2729-996d-43fc-9b72-91000a9c658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224002 (875.01 KB)\n",
      "Trainable params: 224002 (875.01 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def transformation_network(input_shape):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(2)(x)  \n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "input_shape = (28, 28, 1)  \n",
    "model = transformation_network(input_shape)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dacfc4-8766-4945-83ab-048d0b9a20c5",
   "metadata": {},
   "source": [
    "2 пункт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47927ca1-8e18-4a39-807d-035253da747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 1 is to the left of Object 2\n",
      "Object 1 is above Object 2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "image = cv2.imread('image.jpg')\n",
    "\n",
    "\n",
    "object1_x, object1_y = 100, 150\n",
    "object2_x, object2_y = 200, 250\n",
    "\n",
    "\n",
    "if object1_x < object2_x:\n",
    "   print('Object 1 is to the left of Object 2')\n",
    "elif object1_x > object2_x:\n",
    "   print('Object 1 is to the right of Object 2')\n",
    "else:\n",
    "   print('Object 1 and Object 2 are in the same column')\n",
    "\n",
    "if object1_y < object2_y:\n",
    "    print('Object 1 is above Object 2')\n",
    "elif (object1_y > object2_y):\n",
    "    print('Object 1 is below Object 2')\n",
    "else:\n",
    "  print('Object 1 and Object 2 are in the same row')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee1c5b-d253-4862-b7c0-3aaa4afe56b5",
   "metadata": {},
   "source": [
    "3 пункт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9054ef13-c695-484c-9c3f-ca497f6e6b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"CLEVR dataset.\"\"\"\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "\n",
    "from etils import epath\n",
    "import numpy as np\n",
    "from tensorflow_datasets.core.utils.lazy_imports_utils import tensorflow as tf\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "\n",
    "_BASE_URL = \"https://cs.stanford.edu/people/jcjohns/clevr/\"\n",
    "_DOWNLOAD_URL = \"https://dl.fbaipublicfiles.com/clevr/CLEVR_v1.0.zip\"\n",
    "\n",
    "\n",
    "class Build(tfds.core.GeneratorBasedBuilder):\n",
    "  \"\"\"CLEVR dataset.\"\"\"\n",
    "\n",
    "  VERSION = tfds.core.Version(\"3.1.0\")\n",
    "  SUPPORTED_VERSIONS = [\n",
    "      tfds.core.Version(\"3.0.0\"),\n",
    "  ]\n",
    "  RELEASE_NOTES = {\n",
    "      \"3.1.0\": \"Add question/answer text.\",\n",
    "  }\n",
    "\n",
    "  def _info(self):\n",
    "    features = {\n",
    "        \"image\": tfds.features.Image(),\n",
    "        \"file_name\": tfds.features.Text(),\n",
    "        \"objects\": tfds.features.Sequence({\n",
    "            \"color\": tfds.features.ClassLabel(\n",
    "                names=[\n",
    "                    \"gray\",\n",
    "                    \"blue\",\n",
    "                    \"brown\",\n",
    "                    \"yellow\",\n",
    "                    \"red\",\n",
    "                    \"green\",\n",
    "                    \"purple\",\n",
    "                    \"cyan\",\n",
    "                ]\n",
    "            ),\n",
    "            \"material\": tfds.features.ClassLabel(names=[\"rubber\", \"metal\"]),\n",
    "            \"shape\": tfds.features.ClassLabel(\n",
    "                names=[\"cube\", \"sphere\", \"cylinder\"]\n",
    "            ),\n",
    "            \"size\": tfds.features.ClassLabel(names=[\"small\", \"large\"]),\n",
    "            \"rotation\": tfds.features.Tensor(shape=(), dtype=np.float32),\n",
    "            \"3d_coords\": tfds.features.Tensor(shape=(3,), dtype=np.float32),\n",
    "            \"pixel_coords\": tfds.features.Tensor(shape=(3,), dtype=np.float32),\n",
    "        }),\n",
    "    }\n",
    "    if self.version > \"3.0.0\":\n",
    "      features[\"question_answer\"] = tfds.features.Sequence({\n",
    "          \"question\": tfds.features.Text(),\n",
    "          \"answer\": tfds.features.Text(),\n",
    "      })\n",
    "    return self.dataset_info_from_configs(\n",
    "        features=tfds.features.FeaturesDict(features),\n",
    "        homepage=_BASE_URL,\n",
    "    )\n",
    "\n",
    "  def _split_generators(self, dl_manager):\n",
    "    \"\"\"Returns splits.\"\"\"\n",
    "    path = dl_manager.download_and_extract(_DOWNLOAD_URL)\n",
    "\n",
    "    images_path_dir = os.path.join(path, \"CLEVR_v1.0/images\")\n",
    "    questions_path_dir = os.path.join(path, \"CLEVR_v1.0/questions\")\n",
    "    scenes_path_dir = os.path.join(path, \"CLEVR_v1.0/scenes\")\n",
    "\n",
    "    splits = []\n",
    "    for split_name in [\"train\", \"val\", \"test\"]:\n",
    "      name_map = {\n",
    "          \"train\": tfds.Split.TRAIN,\n",
    "          \"val\": tfds.Split.VALIDATION,\n",
    "          \"test\": tfds.Split.TEST,\n",
    "      }\n",
    "      splits.append(\n",
    "          tfds.core.SplitGenerator(\n",
    "              name=name_map[split_name],\n",
    "              gen_kwargs={\n",
    "                  \"images_dir_path\": os.path.join(images_path_dir, split_name),\n",
    "                  \"question_file\": os.path.join(\n",
    "                      questions_path_dir,\n",
    "                      \"CLEVR_{}_questions.json\".format(split_name),\n",
    "                  ),\n",
    "                  \"scenes_description_file\": os.path.join(\n",
    "                      scenes_path_dir, \"CLEVR_{}_scenes.json\".format(split_name)\n",
    "                  ),\n",
    "              },\n",
    "          )\n",
    "      )\n",
    "\n",
    "    return splits\n",
    "\n",
    "  def _generate_examples(\n",
    "      self, images_dir_path, question_file, scenes_description_file\n",
    "  ):\n",
    "    image_paths = sorted(\n",
    "        [\n",
    "            os.path.join(images_dir_path, filename)\n",
    "            for filename in tf.io.gfile.listdir(images_dir_path)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with epath.Path(question_file).open() as f:\n",
    "      questions_json = json.load(f)\n",
    "    questions = collections.defaultdict(list)\n",
    "    for q in questions_json[\"questions\"]:\n",
    "      questions[q[\"image_filename\"]].append({\n",
    "          \"question\": q[\"question\"],\n",
    "          \"answer\": q.get(\"answer\", \"\"),  \n",
    "      })\n",
    "\n",
    "    if tf.io.gfile.exists(scenes_description_file):\n",
    "      with epath.Path(scenes_description_file).open() as f:\n",
    "        scenes_json = json.load(f)\n",
    "    else:\n",
    "      scenes_json = {\"scenes\": [{\"objects\": []}] * len(image_paths)}\n",
    "\n",
    "    attrs = [\n",
    "        \"color\",\n",
    "        \"material\",\n",
    "        \"shape\",\n",
    "        \"size\",\n",
    "        \"rotation\",\n",
    "        \"pixel_coords\",\n",
    "        \"3d_coords\",\n",
    "    ]\n",
    "    for image_path, scene in zip(image_paths, scenes_json[\"scenes\"]):\n",
    "      objects = scene[\"objects\"]\n",
    "      fname = os.path.basename(image_path)\n",
    "      record = {\n",
    "          \"image\": image_path,\n",
    "          \"file_name\": fname,\n",
    "          \"question_answer\": questions[fname],\n",
    "          \"objects\": [{attr: obj[attr] for attr in attrs} for obj in objects],  # pylint: disable=g-complex-comprehension\n",
    "      }\n",
    "      yield fname, record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bb0ec3-a82a-4341-9e70-2181799baa24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
